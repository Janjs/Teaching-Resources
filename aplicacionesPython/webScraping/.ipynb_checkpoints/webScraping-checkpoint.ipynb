{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "\"Rascar la web\". El proceso de obtener información de la web con un proceso de automación usando programación. \n",
    "\n",
    "Hay 3 librerias principales para hacer web scraping en Python, Selenium, Scrapy y Beautiful Soup. Nos centraremos en la última por que és la más intuitiva y es útil en cualquier situación.\n",
    "\n",
    "Cualquier web que pensemos, twitter, instagram, linkedin, podemos obtener la información de ellas.\n",
    "\n",
    "Como lo enseñaré:\n",
    "1. Estructura básica de una web, HTML. \n",
    "2. Web Scraping en una web HTML muy simple para entender los conceptos básicos.\n",
    "3. Web Scraping en una web real.\n",
    "4. Guardar la información que hemos obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Web Scraping en HTML básico\n",
    "\n",
    "Usaremos ./home.html para enseñar un ejemplo.\n",
    "\n",
    "Vemos que la página tiene un título básico y una lista. La lista tiene el título de un curso, su definición, y un botón.\n",
    "\n",
    "Podemos ver el código de la página, empieza con una etiqueta de html que envuelve el resto de la página. La página se divide en head y body.\n",
    "\n",
    "#### head\n",
    "\n",
    "Dentro del head, vemos metadata, que no es relevante. Pero también vemos un link que tiene la función de importar estilos de otro sitio, y el título que define el título tab de la página.\n",
    "\n",
    "#### body / h1\n",
    "\n",
    "En el body es donde definimos lo que sale en la página en si. Podemos encontrar la etiqueta h1, que define título con talla 1. Dentro de la etiqueta definimos el texto que aparecerá con el estilo h1.\n",
    "\n",
    "#### div\n",
    "\n",
    "Luego tenemos la etiqueta div, esta es la etiqueta básica de HTML que basicamente define un espacio en la pantalla. Dentro del div podemos definir sus estilos usando el parámetro \"class\", esto importa el estilo de \"card\". Dentro de este div podemos poner más divs con sus propio estilo (a través de las clases).\n",
    "\n",
    "#### a href\n",
    "\n",
    "Por último, definimos el botón definido con el tag \"a\", que nos indica que esto és un link a otra página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Instalar packages (librerias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cambiar HTML a objetos de Python, necesitamos un **parser**, hay diferentes metodos para parsear. Nosotros usaremos \"lxml\" parser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Cómo scrapear, archivos locales.\n",
    "\n",
    "Beautiful Soup se importa con el nombre bs4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos nuestro conocimiento en manejar archivos con Python para obtener información de home.html. Empezamos con leerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta\n",
      "      name=\"viewport\"\n",
      "      content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"\n",
      "    />\n",
      "    <link\n",
      "      rel=\"stylesheet\"\n",
      "      href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\"\n",
      "      integrity=\"sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z\"\n",
      "      crossorigin=\"anonymous\"\n",
      "    />\n",
      "    <title>My Courses</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1>Hello, Start Learning!</h1>\n",
      "    <div class=\"card\" id=\"card-python-for-beginners\">\n",
      "      <div class=\"card-header\">Python</div>\n",
      "      <div class=\"card-body\">\n",
      "        <h5 class=\"card-title\">Python for beginners</h5>\n",
      "        <p class=\"card-text\">\n",
      "          If you are new to Python, this is the course that you should buy!\n",
      "        </p>\n",
      "        <a href=\"#\" class=\"btn btn-primary\">Start for 20$</a>\n",
      "      </div>\n",
      "    </div>\n",
      "    <div class=\"card\" id=\"card-python-web-development\">\n",
      "      <div class=\"card-header\">Python</div>\n",
      "      <div class=\"card-body\">\n",
      "        <h5 class=\"card-title\">Python Web Development</h5>\n",
      "        <p class=\"card-text\">\n",
      "          If you feel enough confident with python, you are ready to learn how\n",
      "          to create your own website!\n",
      "        </p>\n",
      "        <a href=\"#\" class=\"btn btn-primary\">Start for 50$</a>\n",
      "      </div>\n",
      "    </div>\n",
      "    <div class=\"card\" id=\"card-python-machine-learning\">\n",
      "      <div class=\"card-header\">Python</div>\n",
      "      <div class=\"card-body\">\n",
      "        <h5 class=\"card-title\">Python Machine Learning</h5>\n",
      "        <p class=\"card-text\">Become a Python Machine Learning master!</p>\n",
      "        <a href=\"#\" class=\"btn btn-primary\">Start for 100$</a>\n",
      "      </div>\n",
      "    </div>\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('home.html', 'r') as html_file:\n",
    "    content = html_file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el HTML más leible, usaremos BeautifulSoup. Primero creamos una instáncia de la libreria, pasamos como parametros el código html y el parseador instalado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n",
      "  <link crossorigin=\"anonymous\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\" integrity=\"sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z\" rel=\"stylesheet\"/>\n",
      "  <title>\n",
      "   My Courses\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Hello, Start Learning!\n",
      "  </h1>\n",
      "  <div class=\"card\" id=\"card-python-for-beginners\">\n",
      "   <div class=\"card-header\">\n",
      "    Python\n",
      "   </div>\n",
      "   <div class=\"card-body\">\n",
      "    <h5 class=\"card-title\">\n",
      "     Python for beginners\n",
      "    </h5>\n",
      "    <p class=\"card-text\">\n",
      "     If you are new to Python, this is the course that you should buy!\n",
      "    </p>\n",
      "    <a class=\"btn btn-primary\" href=\"#\">\n",
      "     Start for 20$\n",
      "    </a>\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"card\" id=\"card-python-web-development\">\n",
      "   <div class=\"card-header\">\n",
      "    Python\n",
      "   </div>\n",
      "   <div class=\"card-body\">\n",
      "    <h5 class=\"card-title\">\n",
      "     Python Web Development\n",
      "    </h5>\n",
      "    <p class=\"card-text\">\n",
      "     If you feel enough confident with python, you are ready to learn how\n",
      "          to create your own website!\n",
      "    </p>\n",
      "    <a class=\"btn btn-primary\" href=\"#\">\n",
      "     Start for 50$\n",
      "    </a>\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"card\" id=\"card-python-machine-learning\">\n",
      "   <div class=\"card-header\">\n",
      "    Python\n",
      "   </div>\n",
      "   <div class=\"card-body\">\n",
      "    <h5 class=\"card-title\">\n",
      "     Python Machine Learning\n",
      "    </h5>\n",
      "    <p class=\"card-text\">\n",
      "     Become a Python Machine Learning master!\n",
      "    </p>\n",
      "    <a class=\"btn btn-primary\" href=\"#\">\n",
      "     Start for 100$\n",
      "    </a>\n",
      "   </div>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('home.html', 'r') as html_file:\n",
    "    content = html_file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que con esta página web no haya mucha diferencia, pero cuando trabajemos con webs reales veremos que el código base es complicado de leer.\n",
    "\n",
    "Vamos a empezar a obtener información de esta página \n",
    "\n",
    "----\n",
    "# Beautiful Soup métodos: find & find_all()\n",
    "\n",
    "Vamos a asumir que queremos toda la información que sea un título, a través de la etiqueta \"hN\". Por ejemplo con \"h5\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h5 class=\"card-title\">Python for beginners</h5>\n"
     ]
    }
   ],
   "source": [
    "tags = soup.find('h5')\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordad que teniamos más líneas que usaban h5, por defecto BeautifulSoup después de la primera línea que encuentre dejará de buscar, para cambiarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h5 class=\"card-title\">Python for beginners</h5>, <h5 class=\"card-title\">Python Web Development</h5>, <h5 class=\"card-title\">Python Machine Learning</h5>]\n"
     ]
    }
   ],
   "source": [
    "tags = soup.find_all('h5', )\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si recordais la web, h5 eran los títulos de cada curso, para cada curso podemos mostrar su título entonces usando la variable .text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python for beginners\n",
      "Python Web Development\n",
      "Python Machine Learning\n"
     ]
    }
   ],
   "source": [
    "courses_html_tags = soup.find_all('h5')\n",
    "for course in courses_html_tags:\n",
    "    print(course.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos a ver como podemos conseguir información de la web con técnicas de web scraping.\n",
    "\n",
    "----\n",
    "# Inspect Tool\n",
    "\n",
    "Código web normalmente no suele ser tan \"user-friendly\", tan fácil de leer, por eso en nuestros navegadores podemos usar el inspect tool. Dependerá del navegador que uses, por ejemplo en Google Chrome, click derecho -> inspect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"./imagenes/view1.png\" width=500 height=500 />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el boton de inspeccionar podemos ver la etiqueta por ejemplo del botón ('a')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Proyecto de Scraping básico\n",
    "\n",
    "Podemos borrar el código de los cursos y probar de buscar los bloques de \"targetas\", donde tendremos toda la información del curso.\n",
    "\n",
    "Para saber que atributos del div buscar, usamos el inspector. Podemos ver como todas las targetas de los cursos tienen algo en común, class=\"card\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_cards = soup.find_all('div', class_='card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El underline sirve para decirle a BSoup que es un atributo nativo de html.\n",
    "\n",
    "Si iteramos en cada targeta del curso podemos obtener la información por ejemplo del título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h5 class=\"card-title\">Python for beginners</h5>\n",
      "<h5 class=\"card-title\">Python Web Development</h5>\n",
      "<h5 class=\"card-title\">Python Machine Learning</h5>\n"
     ]
    }
   ],
   "source": [
    "for course in course_cards:\n",
    "    print(course.h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de la etiqueta h5 podemos hacer lo mismo de antes con .text para ver solo el texto, además de otras variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python for beginners: Start for 20$\n",
      "Python Web Development: Start for 50$\n",
      "Python Machine Learning: Start for 100$\n"
     ]
    }
   ],
   "source": [
    "course_cards = soup.find_all('div', class_='card')\n",
    "for course in course_cards:\n",
    "    course_name = course.h5.text\n",
    "    course_price = course.a.text\n",
    "    print(course_name+\": \"+course_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos dividir el texto del precio para solo obtener el número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python for beginners vale 20$\n",
      "Python Web Development vale 50$\n",
      "Python Machine Learning vale 100$\n"
     ]
    }
   ],
   "source": [
    "course_cards = soup.find_all('div', class_='card')\n",
    "for course in course_cards:\n",
    "    course_name = course.h5.text\n",
    "    course_price = course.a.text.split()[-1]\n",
    "    print(course_name+\" vale \"+course_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la utilidad de web scraping, por ejemplo podriamos hacer un bot que este permanentemente buscando un precio de algo en Amazon y cuando sea mas bajo que x, lo compramos.\n",
    "\n",
    "Código final de esta fase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python for beginners vale 20$\n",
      "Python Web Development vale 50$\n",
      "Python Machine Learning vale 100$\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('home.html', 'r') as html_file:\n",
    "    content = html_file.read()\n",
    "\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    course_cards = soup.find_all('div', class_='card')\n",
    "    for course in course_cards:\n",
    "        course_name = course.h5.text\n",
    "        course_price = course.a.text.split()[-1]\n",
    "        print(course_name+\" vale \"+course_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Usando libreria request para ver el HTML de una página web\n",
    "\n",
    "Si la web que queremos scrapear no la tenemos localmente, podemos conseguir el código con la libreria request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que escoger una web que escrapear, se ha de tener en mente que los desarrolladores de la web pueden modificar el código en un futuro y nuestro código puede dejar de funcionar.\n",
    "\n",
    "Usaremos linkedin como ejemplo:\n",
    "\n",
    "**ABRIRLO EN ICOGNITO**\n",
    "\n",
    "https://www.linkedin.com/jobs/\n",
    "\n",
    "Si buscamos ofertas de Python en Mataro:\n",
    "\n",
    "https://www.infojobs.net/ofertas-trabajo?keyword=python&normalizedJobTitleIds=&provinceIds=&cityIds=&categoryIds=&workdayIds=&educationIds=&segmentId=&contractTypeIds=&page=1&sortBy=&onlyForeignCountry=false&countryIds=&sinceDate=ANY&subcategoryIds=\n",
    "\n",
    "Veremos muchos trabajos de python.\n",
    "\n",
    "Nuestro objetivo será conseguir ver los trabajos que son de hoy.\n",
    "\n",
    "Para obtener el código de esta página en Python usamos la libreria request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://www.linkedin.com/jobs/search?keywords=Python&location=Matar%C3%B3%2C%20Catalonia%2C%20Spain&geoId=101156716&trk=public_jobs_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0'\n",
    "html_text = requests.get(url)\n",
    "html_text = html_text.text\n",
    "#print(html_text) # nos mostrará todo el código de la página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el mismo método que antes con el parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos obtener la información de cada trabajo, tenemos que inspeccionar para ver como son sus etiquetas.\n",
    "\n",
    "<div>\n",
    "    <img src=\"./imagenes/view2.png\" width=500 height=500 />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conseguir todos los trabajos disponibles usamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"result-card__contents job-result-card__contents\">\n",
      " <h3 class=\"result-card__title job-result-card__title\">\n",
      "  Junior Python developer\n",
      " </h3>\n",
      " <h4 class=\"result-card__subtitle job-result-card__subtitle\">\n",
      "  <a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-client-ingraph=\"\" data-tracking-control-name=\"public_jobs_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://es.linkedin.com/company/getwith?trk=public_jobs_job-result-card_result-card_subtitle-click\">\n",
      "   GetWith\n",
      "  </a>\n",
      " </h4>\n",
      " <div class=\"result-card__meta job-result-card__meta\">\n",
      "  <span class=\"job-result-card__location\">\n",
      "   Barcelona, Catalonia, Spain\n",
      "  </span>\n",
      "  <p class=\"job-result-card__snippet\">\n",
      "   Experience using git and using Linux systems. Proven experience developing python based projects end to end. Our client is engineering a ...\n",
      "  </p>\n",
      "  <time class=\"job-result-card__listdate\" datetime=\"2021-02-04\">\n",
      "   2 days ago\n",
      "  </time>\n",
      " </div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "job = soup.find('div', class_=\"result-card__contents job-result-card__contents\")\n",
    "print(job.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del código podemos buscar por el título por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Junior Python developer\n"
     ]
    }
   ],
   "source": [
    "job_title = job.find('h3', class_=\"result-card__title job-result-card__title\").text\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Podemos hacer lo mismo con el nombre de empresa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GetWith\n"
     ]
    }
   ],
   "source": [
    "company_name = job.find('a', class_=\"result-card__subtitle-link job-result-card__subtitle-link\").text\n",
    "print(company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Con más trucos de print podemos mostrar los valores de esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Company Name: GetWith\n",
      "Job title: Junior Python developer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Company Name: {company_name}\n",
    "Job title: {job_title}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Recordad que queremos obtener cuando se posteo el trabajo, si nos fijamos tenemos una etiqueta \"time\" con esa información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04\n"
     ]
    }
   ],
   "source": [
    "published_date = job.find('time', class_=\"job-result-card__listdate\")[\"datetime\"]\n",
    "print(published_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now we need to do the same for every job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = soup.find_all(\n",
    "    'div', class_=\"result-card__contents job-result-card__contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Company Name: GetWith\n",
      "    Job title: Junior Python developer\n",
      "    published at: 2021-02-04\n",
      "    \n",
      "\n",
      "    Company Name: Grupo Empresarial Español\n",
      "    Job title: Programador Python\n",
      "    published at: 2021-02-06\n",
      "    \n",
      "\n",
      "    Company Name: Grupo Empresarial Español\n",
      "    Job title: Programador Python\n",
      "    published at: 2021-02-05\n",
      "    \n",
      "\n",
      "    Company Name: Experis Selección\n",
      "    Job title: Programador/a Python\n",
      "    published at: 2021-01-14\n",
      "    \n",
      "\n",
      "    Company Name: Fiction Express\n",
      "    Job title: Desarrollador backend junior\n",
      "    published at: 2021-01-13\n",
      "    \n",
      "\n",
      "    Company Name: Fiction Express\n",
      "    Job title: Desarrollador backend junior, Barcelona\n",
      "    published at: 2021-02-06\n",
      "    \n",
      "\n",
      "    Company Name: Apple\n",
      "    Job title: AI/ML- Machine Learning Internship- Machine Intelligence, Spain\n",
      "    published at: 2021-02-02\n",
      "    \n",
      "\n",
      "    Company Name: Experis\n",
      "    Job title: Programador Python\n",
      "    published at: 2021-01-20\n",
      "    \n",
      "\n",
      "    Company Name: Tech Data\n",
      "    Job title: Developer Junior - Python\n",
      "    published at: 2021-01-23\n",
      "    \n",
      "\n",
      "    Company Name: Walters People Spain\n",
      "    Job title: Junior Java/Python Developer\n",
      "    published at: 2021-01-25\n",
      "    \n",
      "\n",
      "    Company Name: Acellera\n",
      "    Job title: Junior scientific front-end developer\n",
      "    published at: 2021-02-05\n",
      "    \n",
      "\n",
      "    Company Name: open3s\n",
      "    Job title: Programador/A Backend Junior Big Data\n",
      "    published at: 2021-02-03\n",
      "    \n",
      "\n",
      "    Company Name: Altair\n",
      "    Job title: Python Developer\n",
      "    published at: 2020-10-17\n",
      "    \n",
      "\n",
      "    Company Name: peoplegofirst\n",
      "    Job title: Python developer\n",
      "    published at: 2020-10-13\n",
      "    \n",
      "\n",
      "    Company Name: Nuvolar Works\n",
      "    Job title: Python Developer\n",
      "    published at: 2020-10-17\n",
      "    \n",
      "\n",
      "    Company Name: Q-tech\n",
      "    Job title: Python Fullstack Engineer\n",
      "    published at: 2021-01-25\n",
      "    \n",
      "\n",
      "    Company Name: OPEN3S\n",
      "    Job title: Programador/a backend junior Big Data\n",
      "    published at: 2021-02-03\n",
      "    \n",
      "\n",
      "    Company Name: Glovo\n",
      "    Job title: Junior Growth Analyst\n",
      "    published at: 2021-02-05\n",
      "    \n",
      "\n",
      "    Company Name: Q-Tech Recruitment Consultants\n",
      "    Job title: Python Engineer\n",
      "    published at: 2021-01-25\n",
      "    \n",
      "\n",
      "    Company Name: #AttittudTalent #Attittud Business\n",
      "    Job title: Python Developer\n",
      "    published at: 2021-01-30\n",
      "    \n",
      "\n",
      "    Company Name: HP\n",
      "    Job title: Data Analyst Internship\n",
      "    published at: 2021-02-05\n",
      "    \n",
      "\n",
      "    Company Name: Amazon\n",
      "    Job title: ML Scientist\n",
      "    published at: 2021-02-06\n",
      "    \n",
      "\n",
      "    Company Name: Altran\n",
      "    Job title: Image Processing/ Python Engineer (F/M)\n",
      "    published at: 2021-01-31\n",
      "    \n",
      "\n",
      "    Company Name: MANGO\n",
      "    Job title: Insights Data Scientist \n",
      "    published at: 2021-01-28\n",
      "    \n",
      "\n",
      "    Company Name: Elements\n",
      "    Job title: Python/Django Developer\n",
      "    published at: 2020-11-23\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for job in jobs:\n",
    "    try:\n",
    "        company_name = job.find('a').text\n",
    "    except:\n",
    "        company_name = job.find('h4').text\n",
    "    job_title = job.find('h3').text\n",
    "    published_date = job.find('time')[\"datetime\"]\n",
    "\n",
    "    print(f'''\n",
    "    Company Name: {company_name}\n",
    "    Job title: {job_title}\n",
    "    published at: {published_date}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Falta filtrar los trabajos que son de hoy, para eso importamos la libreria datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Company Name: Grupo Empresarial Español\n",
      "        Job title: Programador Python\n",
      "        published at: 2021-02-06\n",
      "        \n",
      "\n",
      "        Company Name: Fiction Express\n",
      "        Job title: Desarrollador backend junior, Barcelona\n",
      "        published at: 2021-02-06\n",
      "        \n",
      "\n",
      "        Company Name: Amazon\n",
      "        Job title: ML Scientist\n",
      "        published at: 2021-02-06\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "for job in jobs:\n",
    "    published_date = job.find('time')[\"datetime\"]\n",
    "    if published_date == datetime.today().strftime('%Y-%m-%d'):\n",
    "        try:\n",
    "            company_name = job.find('a').text\n",
    "        except:\n",
    "            company_name = job.find('h4').text\n",
    "        job_title = job.find('h3').text\n",
    "\n",
    "        print(f'''\n",
    "        Company Name: {company_name}\n",
    "        Job title: {job_title}\n",
    "        published at: {published_date}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "No hay límite con lo que podemos hacer con web scraping!\n",
    "\n",
    "----\n",
    "# Haciendo el programa mas útil\n",
    "\n",
    "Podemos añadir más información como el link.\n",
    "\n",
    "Para eso tenemos que ir un paso más atras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Company Name: Grupo Empresarial Español\n",
      "        Job title: Programador Python\n",
      "        published at: 2021-02-06\n",
      "        \n",
      "\n",
      "        Company Name: Fiction Express\n",
      "        Job title: Desarrollador backend junior, Barcelona\n",
      "        published at: 2021-02-06\n",
      "        \n",
      "\n",
      "        Company Name: Amazon\n",
      "        Job title: ML Scientist\n",
      "        published at: 2021-02-06\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "jobs = soup.find_all(\n",
    "    'li', class_=\"result-card\")\n",
    "\n",
    "for job_full in jobs:\n",
    "    job = job_full.find(\n",
    "        'div', class_=\"result-card__contents job-result-card__contents\")\n",
    "\n",
    "    published_date = job.find('time')[\"datetime\"]\n",
    "\n",
    "    if published_date == datetime.today().strftime('%Y-%m-%d'):\n",
    "        try:\n",
    "            company_name = job.find('a').text\n",
    "        except:\n",
    "            company_name = job.find('h4').text\n",
    "        job_title = job.find('h3').text\n",
    "\n",
    "        print(f'''\n",
    "        Company Name: {company_name}\n",
    "        Job title: {job_title}\n",
    "        published at: {published_date}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Ahora ya podemos conseguir el link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Company Name: Grupo Empresarial Español\n",
      "        Job title: Programador Python\n",
      "        published at: 2021-02-06\n",
      "        link: https://es.linkedin.com/jobs/view/programador-python-at-grupo-empresarial-espa%C3%B1ol-2412200112?refId=ccda510f-651e-4d68-87c0-45055ed54652&trackingId=VtP3RkDmVPP9%2BPA3IVvGmQ%3D%3D&position=2&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click\n",
      "        \n",
      "\n",
      "        Company Name: Fiction Express\n",
      "        Job title: Desarrollador backend junior, Barcelona\n",
      "        published at: 2021-02-06\n",
      "        link: https://es.linkedin.com/jobs/view/desarrollador-backend-junior-barcelona-at-fiction-express-2412094961?refId=ccda510f-651e-4d68-87c0-45055ed54652&trackingId=%2B3fqIqTLgysYIo2iD3nY9w%3D%3D&position=6&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click\n",
      "        \n",
      "\n",
      "        Company Name: Amazon\n",
      "        Job title: ML Scientist\n",
      "        published at: 2021-02-06\n",
      "        link: https://es.linkedin.com/jobs/view/ml-scientist-at-amazon-2391495268?refId=ccda510f-651e-4d68-87c0-45055ed54652&trackingId=52nkZ9JMMzGhNWFwWIDcPg%3D%3D&position=22&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "for job_full in jobs:\n",
    "    link = job_full.a['href']\n",
    "\n",
    "    job = job_full.find(\n",
    "        'div', class_=\"result-card__contents job-result-card__contents\")\n",
    "\n",
    "    published_date = job.find('time')[\"datetime\"]\n",
    "\n",
    "    if published_date == datetime.today().strftime('%Y-%m-%d'):\n",
    "        try:\n",
    "            company_name = job.find('a').text\n",
    "        except:\n",
    "            company_name = job.find('h4').text\n",
    "        job_title = job.find('h3').text\n",
    "\n",
    "        print(f'''\n",
    "        Company Name: {company_name}\n",
    "        Job title: {job_title}\n",
    "        published at: {published_date}\n",
    "        link: {link}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Bot para ejecutar el código cada 10 minutos\n",
    "\n",
    "Primero ponemos todo el código dentro de una función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jobs():\n",
    "    html_text = requests.get(url)\n",
    "    html_text = html_text.text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    jobs = soup.find_all(\n",
    "        'li', class_=\"result-card\")\n",
    "\n",
    "    for job_full in jobs:\n",
    "        link = job_full.a['href']\n",
    "\n",
    "        job = job_full.find(\n",
    "            'div', class_=\"result-card__contents job-result-card__contents\")\n",
    "        \n",
    "        published_date = job.find('time')[\"datetime\"]\n",
    "\n",
    "        if published_date == datetime.today().strftime('%Y-%m-%d'):\n",
    "            try:\n",
    "                company_name = job.find('a').text\n",
    "            except:\n",
    "                company_name = job.find('h4').text\n",
    "            job_title = job.find('h3').text\n",
    "\n",
    "            print(f'''\n",
    "            Company Name: {company_name}\n",
    "            Job title: {job_title}\n",
    "            published at: {published_date}\n",
    "            link: {link}\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python, si ejecutamos este fichero, podemos especificar que queremos que se ejecute dentro de una función llamada **main**.\n",
    "\n",
    "Dentro de este main podemos poner un bucle que sea siempre True, llamamos a la función time.sleep() el tiempo que queramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobs()\n",
    "        time_wait = 10\n",
    "        print(f'Waiting {time_wait} minutes...') \n",
    "        time.sleep(time_wait * 60) # en minutos, 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Funciona!!\n",
    "\n",
    "# Escribir la información en otro archivo\n",
    "\n",
    "Seria interesante poder guardar la información en un archivo. Primero creamos una carpeta para guardar esa información. La llamamos como queramos, por ejemplo ./jops\n",
    "\n",
    "Ahora simplemente podemos abrir un nuevo archivo en python y escribir en el:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jobs():\n",
    "    html_text = requests.get(url)\n",
    "    html_text = html_text.text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    jobs = soup.find_all(\n",
    "        'li', class_=\"result-card\")\n",
    "\n",
    "    for index, job_full in enumerate(jobs):\n",
    "        link = job_full.a['href']\n",
    "\n",
    "        job = job_full.find(\n",
    "            'div', class_=\"result-card__contents job-result-card__contents\")\n",
    "\n",
    "        published_date = job.find('time')[\"datetime\"]\n",
    "\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "        if published_date == today:\n",
    "            try:\n",
    "                company_name = job.find('a').text\n",
    "            except:\n",
    "                company_name = job.find('h4').text\n",
    "            job_title = job.find('h3').text\n",
    "\n",
    "            with open(f'jobs/{str(today) + \" \" +str(index)}.txt', 'w') as f:\n",
    "                f.write(f'''\n",
    "                Company Name: {company_name}\n",
    "                Job title: {job_title}\n",
    "                published at: {published_date}\n",
    "                link: {link}\n",
    "                ''')\n",
    "            print(f'File saved: {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: 1\n",
      "File saved: 18\n"
     ]
    }
   ],
   "source": [
    "find_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
